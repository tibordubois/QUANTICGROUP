\section{Recherche d'un nombre inconnu de solutions}
\label{part3}

Dans les sections précédentes, nous avons connaissance du nombre de solutions présentes dans l'ensemble de recherche, ce qui permet à l'estimation du nombre optimale d'itérations de l'algorithme aboutissant à une probabilité maximale de succès lors de la mesure. Cependant, il s'avère que même en étant contraint à un nombre de solutions inconnus, un algorithme quantique peut tout de même trouver une solution en $\mathcal{O}(\sqrt{N})$. \cite{brassard2002quantum}

\subsection{Lemme}
\label{Lemme}

Soit $M$ le nombre (inconnu) de solutions et $\theta = \mathrm{arcsin}(\sqrt{M/N})$. Soit $m \in \mathbb{N}$ et $j$ choisi uniformément dans l'intervalle $[\![0, m-1]\!]$.
\\
L'algorithme de Grover appliqué sur l'état initial $| \psi \rangle = \frac{1}{\sqrt{N}} \sum_{k=0}^{N-1} |k\rangle$ retourne une solution après $j$ itérations avec une probabilité donnée par:
\[P_m = \frac{1}{2} - \frac{\mathrm{sin}(4\theta)}{4m\mathrm{sin(2\theta)}}\]
Avec en particulier $P_m \geq 1/4$ pour $m \geq 1/\mathrm{sin}(2\theta)$.
\\
\textit{Preuve:} Remarquons dans un premier temps que pour tout $\alpha, \beta \in \mathbb{R}$:
\[ \sum_{k=0}^{m-1}\mathrm{cos}(\alpha + 2\beta k) = \frac{\mathrm{sin}(m\beta)\mathrm{cos}(\alpha+(m-1)\beta)}{\mathrm{sin}(\beta)}\]
Notamment pour $\alpha=\beta$, nous avons:
\begin{align}
\sum_{k=0}^{m-1}\mathrm{cos}((2k+1)\alpha) = \frac{\mathrm{sin}(2m\alpha)}{2\mathrm{sin}(\alpha)}
\label{eq:3}
\end{align}
Ainsi, sachant que la probabilité d'obtenir une solution après $j$ itérations de l'algorithme de Grover est précisément $\mathrm{sin}^2((2j+1)\theta)$, pour $J_m \sim \mathcal{U}(0,m-1)$ une variable aléatoire suivant une loi uniforme discrète sur $[\![0,m-1]\!]$, on a par la formule du transfert:
\begin{align*}
P_m =&\ \mathbb{E}(\mathrm{sin}^2((2J+1)\theta)) \\
=&\ \sum_{j=0}^{m-1}\mathrm{sin}^2((2j+1)\theta) \frac{1}{m} \\
=&\ \frac{1}{2m} \sum_{j=0}^{m-1}1 - \mathrm{cos}^2((2j+1)2\theta) \\
=&\ \frac{1}{2} - \frac{\mathrm{sin}(4\theta)}{4m\mathrm{sin(2\theta)}}
\end{align*}
D'après l'identité \eqref{eq:3}. Si $m \geq 1/\mathrm{sin}(2\theta)$, alors:
\[\frac{\mathrm{sin}(4\theta)}{4m\mathrm{sin(2\theta)}} \leq \frac{1}{4m\mathrm{sin(2\theta)}} \leq \frac{1}{4}\]
D'où le résultat.

\subsection{Algorithme}
Supposons au premier abord que $1 \leq M \leq 3N/4$. Soit $i$ l'itérateur de la boucle externe:
\begin{itemize}
	\item[1] Initialiser $m_{(0)}=1$ et $\lambda \in ]1, 4/3[$.
	\item[2] Choisir $j_{(i)}$ uniformément dans $[\![0, m_{(i)}-1]\!]$.
	\item[3] Effectuer $j_{(i)}$ itérations de l'algorithme de Grover en partant de l'état initial $| \psi \rangle = \frac{1}{\sqrt{N}} \sum_{k=0}^{N-1} |k\rangle$.
	\item[4] Mesurer le vecteur d'état $| \psi_{(j_{(i)})} \rangle$: Soit $t$ le résultat.
	\item[5]
	\begin{itemize}
    	\item[5.1] Si $t$ est solution: Fin de l'algorithme.
    	\item[5.2] Sinon: $m_{(i+1)} = \mathrm{min}(\lceil \lambda m_{(i)} \rceil, \sqrt{N})$ et retourner à l'étape 2.
	\end{itemize}
\end{itemize}

\subsection{Complexité}
L'algorithme ci-dessus trouve une solution avec une complexité en espérance de $\mathcal{O}(\sqrt{N/M})$.
\\
\textit{Preuve:} Reprennons $\theta = \mathrm{arcsin}(\sqrt{M/N})$. On pose: \[\tilde{m} = 1/\mathrm{sin}(2\theta) = \frac{N}{2\sqrt{M(N-M)}} < \sqrt{N/M}\]
\\
Il s'agit ici d'estimer le nombre d'applications de l'itération de Grover en espérance. À la $i$-ème itération de la boucle principale, la valeur de $m_{(i)}$ est environ $\lambda^{i-1}$ et le nombre $j_{(i)}$ d'itérations est en moyenne la moitié de $m_{(i)}$.
On dit que l'algorithme atteint son \textit{état critique} dès lors que $i$ dépasse $\lceil \mathrm{log}_{\lambda}\tilde{m} \rceil$. Remarquons ici que la valeur de $m_{(i)}$ dépasse $\tilde{m}$ après ce stage.
\\
Le nombre d'itérations en espérance requis pour atteindre l'état critique est majoré par:
\[\sum_{s=1}^{\lceil \mathrm{log}_{\lambda}\tilde{m} \rceil} \mathbb{E}(J_{\lceil \lambda^{s-1}\rceil}) \approx \frac{1}{2} \sum_{s=1}^{\lceil \mathrm{log}_{\lambda}\tilde{m} \rceil} \lambda^{s-1} < \frac{\lambda}{2\lambda-2}\tilde{m} = \mathcal{O}(\tilde{m})\]
Ainsi, si l'algorithme trouve une solution avant d'arriver à l'état critique, il le trouve en $\mathcal{O}(\tilde{m})$ donc $\mathcal{O}(\sqrt{N/M})$.
\\
Si l'état critique est atteint, chaque itération postérieure trouve une solution avec une probabilité supérieure à $1/4$ en vertu du Lemme \ref{Lemme}.
Nous pouvons ainsi représenter le résultat pire-cas de l'algorithme après $\lceil \mathrm{log}_{\lambda}\tilde{m} \rceil$ itérations par une épreuve de Bernoulli $X \sim \mathcal{B}(1/4)$ où l'issue de succès signifie que l'algorithme a trouvé un résultat.
Posons de plus à partir de $X$ la variable $I \sim \mathcal{G}(1/4)$ suivant une loi géométrique. Celle-ci compte le nombre d'itérations de la boucle externe avant d'obtenir une solution.
\\
Sachant qu'à la $i$-ème itération (après avoir atteint l'état critique) nous avons $j_{(i)}$ itérations de l'algorithme de Grover, avec $j_{(i)}$ donné par $J_{\lceil \lambda^{i-1}\rceil + \lceil \mathrm{log}_{\lambda}\tilde{m} \rceil}$, on en déduit l'espérance du nombre total d'itération de l'algorithme de Grover post état critique:
\begin{align*}
\mathbb{E}(J_{\lceil \lambda^{I-1}\rceil + \lceil \mathrm{log}_{\lambda}\tilde{m} \rceil})
=&\ \sum_{i=1}^{\infty} \left( \frac{3}{4} \right) ^{i-1} \! \left( \frac{1}{4} \right) \mathbb{E}(J_{\lceil \lambda^{i-1}\rceil + \lceil \mathrm{log}_{\lambda}\tilde{m} \rceil}) \\
\approx&\ \frac{1}{2} \sum_{s=0}^{\infty} \frac{3^s}{4^{s+1}}\lambda^{s+\lceil \mathrm{log}_{\lambda}\tilde{m} \rceil} \\
<&\ \frac{\lambda}{8-6\lambda}\tilde{m} = \mathcal{O}(\tilde{m})
\end{align*}
\\
En sommant les deux majorations, nous avons une complexité totale en
\[\frac{\lambda}{2\lambda-2}\tilde{m} + \frac{\lambda}{8-6\lambda}\tilde{m} = \mathcal{O}(\tilde{m}) = \mathcal{O}(\sqrt{N/M})\] pour $0<M \leq 3N/4$.
\\
La cas où $M > 3N/4$ se traite avec une complexité en espérance constante par échantillonnage classique. Enfin pour $M = 0$, il s'agit d'implémenter un temps mort approprié permettant d'affirmer qu'il n'existe aucune solution en un temps de $\mathcal{O}(\sqrt{N})$. La probabilité d'échec peut être rendue arbitrairement faible quand il existe en réalité une solution. 